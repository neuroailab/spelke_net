<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Discovering and using Spelke segments">
  <meta name="keywords" content="Segmentation, Computer Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Discovering and using Spelke segments</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/website_logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Discovering and using Spelke segments</h1>

          <!-- Smaller font size applied here -->
          <div style="font-size: 0.85rem;">
            <div class="is-size-6 publication-authors">
              <div>
              <span class="author-block">
                <a href="https://rahulvenkk.github.io/" target="_blank" rel="noopener noreferrer">Rahul Venkatesh</a><sup>*1</sup>,
              <span class="author-block">
                <a href="https://klemenkotar.github.io/" target="_blank" rel="noopener noreferrer">Klemen Kotar</a><sup>*1</sup>,
              <span class="author-block">
                <a href="https://www.linkedin.com/in/lilian-chen-1975b81b1/" target="_blank" rel="noopener noreferrer">Lilian Naing Chen</a><sup>*1</sup>,
              <span class="author-block">
                <a href="https://www.linkedin.com/in/seungwoo-simon-kim/" target="_blank" rel="noopener noreferrer">Seungwoo Kim</a><sup>1</sup>,
              <span class="author-block">
                <a href="https://www.linkedin.com/in/luca-wheeler-180818244/" target="_blank" rel="noopener noreferrer">Luca Thomas Wheeler</a><sup>1</sup>,
              <span class="author-block">
                <a href="https://www.linkedin.com/in/jared-watrous/" target="_blank" rel="noopener noreferrer">Jared Watrous</a><sup>1</sup>,
              </div>
              <div>
                <span class="author-block">
                <a href="https://www.linkedin.com/in/ashley-xu-a2588b1a9/" target="_blank" rel="noopener noreferrer">Ashley Xu</a><sup>1</sup>,
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/gia-ancone-58b545207/" target="_blank" rel="noopener noreferrer">Gia Ancone</a><sup>1</sup>,
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/wanhee-lee-31102820b/" target="_blank" rel="noopener noreferrer">Wanhee Lee</a><sup>1</sup>,
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/honglin-chen-52b13712a/" target="_blank" rel="noopener noreferrer">Honglin Chen</a><sup>2</sup>,
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/daniel-bear-b79480279/" target="_blank" rel="noopener noreferrer">Daniel Bear</a><sup>3</sup>,
                <span class="author-block">
                  <a href="https://sstojanov.github.io/" target="_blank" rel="noopener noreferrer">Stefan Stojanov</a><sup>1</sup>,
                <span class="author-block">
                  <a href="https://web.stanford.edu/~yamins/" target="_blank" rel="noopener noreferrer">Daniel Yamins</a><sup>1</sup>

              </div>
            </div>

            <div class="is-size-6 publication-authors" style="margin-top: 0.5em;">
              <span class="author-block"><sup>1</sup>Stanford University,</span>
              <span class="author-block"><sup>2</sup>OpenAI,</span>
              <span class="author-block"><sup>3</sup>Noetik Inc.</span>
            </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://neuroailab.github.io/spelke_net/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://neuroailab.github.io/spelke_net/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://neuroailab.github.io/spelke_net/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://neuroailab.github.io/spelke_net/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  #teaser {
    width: 100%;
    height: auto;
    display: block;
    border-radius: 8px;
  }
  
  /* Custom video controls styling */
  .video-controls {
    margin-top: 1rem;
    display: flex;
    align-items: center;
    gap: 1rem;
    padding: 0.5rem;
    background: rgba(0, 0, 0, 0.05);
    border-radius: 8px;
  }
  
  .play-pause-btn {
    background: #333;
    color: white;
    border: none;
    border-radius: 50%;
    width: 40px;
    height: 40px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 12px;
    transition: background 0.2s;
  }
  
  .play-pause-btn:hover {
    background: #555;
  }
  
  .scrubber-container {
    flex: 1;
    position: relative;
  }
  
  .scrubber {
    width: 100%;
    height: 4px;
    border-radius: 2px;
    background: #ddd;
    outline: none;
    cursor: pointer;
    -webkit-appearance: none;
    appearance: none;
  }
  
  .scrubber::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 12px;
    height: 12px;
    border-radius: 50%;
    background: #333;
    cursor: pointer;
    transition: transform 0.2s;
  }
  
  .scrubber::-webkit-slider-thumb:hover {
    transform: scale(1.2);
  }
  
  .scrubber::-moz-range-thumb {
    width: 12px;
    height: 12px;
    border-radius: 50%;
    background: #333;
    cursor: pointer;
    border: none;
    transition: transform 0.2s;
  }
  
  .scrubber::-moz-range-thumb:hover {
    transform: scale(1.2);
  }
  
  .time-display {
    color: #666;
    font-size: 14px;
    font-family: monospace;
    white-space: nowrap;
  }
  
  .progress-bar {
    position: absolute;
    top: 0;
    left: 0;
    height: 4px;
    background: #333;
    border-radius: 2px;
    pointer-events: none;
    transition: width 0.1s;
  }
</style>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline>
        <source src="./static/videos/teaser.mov"
                type="video/mp4">
      </video>
      
      <div class="video-controls">
        <button class="play-pause-btn" id="playPauseBtn">❚❚</button>
        
        <div class="scrubber-container">
          <div class="progress-bar" id="progressBar"></div>
          <input type="range" class="scrubber" id="scrubber" min="0" max="100" value="0">
        </div>
        
        <div class="time-display">
          <span id="currentTime">0:00</span> / <span id="duration">0:00</span>
        </div>
      </div>
      
      <h2 class="subtitle 6 has-text-grey mt-4" style="font-style: italic; text-align:justify">
        <strong>Overview of SpelkeNet's Capabilities.</strong> 
        On the <strong>left</strong>, our model first predicts a probability of motion map, indicating regions likely to move if an external force is applied. 
        We sample a point from this map, apply a virtual poke, and have the model complete a flow field revealing which other pixels will move as a result of this poke. From this,
        we can naturally extract a group of pixels which move together—i.e. a Spelke segment.
        On the <strong>right</strong>, we illustrate how these discovered segments can enable more physically plausible object manipulation.
      </h2>
    </div>
  </div>
</section>

<script>
  document.addEventListener('DOMContentLoaded', function() {
    const video = document.getElementById('teaser');
    const playPauseBtn = document.getElementById('playPauseBtn');
    const scrubber = document.getElementById('scrubber');
    const progressBar = document.getElementById('progressBar');
    const currentTimeSpan = document.getElementById('currentTime');
    const durationSpan = document.getElementById('duration');
    
    let isDragging = false;
    
    // Format time helper with better error handling
    function formatTime(seconds) {
      if (isNaN(seconds) || !isFinite(seconds)) {
        return '0:00';
      }
      const mins = Math.floor(seconds / 60);
      const secs = Math.floor(seconds % 60);
      return `${mins}:${secs.toString().padStart(2, '0')}`;
    }
    
    // Initialize controls when video metadata is ready
    function initializeControls() {
      if (video.duration && isFinite(video.duration)) {
        durationSpan.textContent = formatTime(video.duration);
        scrubber.max = 100; // Use percentage instead of seconds
        scrubber.value = 0;
        progressBar.style.width = '0%';
        currentTimeSpan.textContent = formatTime(0);
      }
    }
    
    // Update duration when metadata loads
    video.addEventListener('loadedmetadata', initializeControls);
    
    // Also try to initialize if metadata is already loaded
    if (video.readyState >= 1) {
      initializeControls();
    }
    
    // Update scrubber and time as video plays
    video.addEventListener('timeupdate', () => {
      if (!isDragging && video.duration && isFinite(video.duration)) {
        const percentage = (video.currentTime / video.duration) * 100;
        scrubber.value = percentage;
        progressBar.style.width = percentage + '%';
        currentTimeSpan.textContent = formatTime(video.currentTime);
      }
    });
    
    // Play/pause functionality
    playPauseBtn.addEventListener('click', () => {
      if (video.paused) {
        video.play();
        playPauseBtn.textContent = '❚❚';
      } else {
        video.pause();
        playPauseBtn.textContent = '▶';
      }
    });
    
    // Scrubber functionality - convert percentage back to time
    scrubber.addEventListener('input', () => {
      if (video.duration && isFinite(video.duration)) {
        const percentage = scrubber.value;
        const newTime = (percentage / 100) * video.duration;
        progressBar.style.width = percentage + '%';
        currentTimeSpan.textContent = formatTime(newTime);
      }
    });
    
    scrubber.addEventListener('mousedown', () => {
      isDragging = true;
    });
    
    scrubber.addEventListener('mouseup', () => {
      isDragging = false;
      if (video.duration && isFinite(video.duration)) {
        const percentage = scrubber.value;
        video.currentTime = (percentage / 100) * video.duration;
      }
    });
    
    scrubber.addEventListener('change', () => {
      isDragging = false;
      if (video.duration && isFinite(video.duration)) {
        const percentage = scrubber.value;
        video.currentTime = (percentage / 100) * video.duration;
      }
    });
    
    // Handle video play/pause on click
    video.addEventListener('click', () => {
      playPauseBtn.click();
    });
    
    // Update play button state when video ends
    video.addEventListener('ended', () => {
      playPauseBtn.textContent = '▶';
    });
  });
</script>

</body>

<section class="section" style="padding-top: 1rem;">

  <div class="container is-max-desktop">

    <!-- SEC 1: Defining Spelke Objects -->
    <div class="content">
      <h2 class="has-text-weight-bold is-size-5 mb-4">Existing definitions of segmentation may not be sufficient for physical reasoning tasks</h2>

      <!-- Main body paragraph -->
      <div class="content has-text-justified mt-5 is-size-6">
        <p>
          An ongoing challenge in image segmentation is defining segments with arbitrary categories, 
          as existing segmentation datasets like <a href="https://cocodataset.org/#home" target="_blank" rel="noopener noreferrer">COCO</a> and <a href="https://ade20k.csail.mit.edu/" target="_blank" rel="noopener noreferrer">ADE20K</a> 
          rely on semantic labels (e.g. car, tree, sky) to define segments.
          Although these are useful for recognition tasks, the resulting masks often do not reflect how objects move or interact in the real world, 
          effectively limiting their utility in robotics tasks like object manipulation, which require physical reasoning capabilities to understand which parts of a scene move together.
        </p>
      </div>

    </div>


    <!-- SEC 1: Defining Spelke Objects -->
    <div class="content">
      <h2 class="has-text-weight-bold is-size-5 mb-4">Spelke segments---i.e. segments defined based on motion correlation---address this limitation</h2>

      <!-- Main body paragraph -->
      <div class="content has-text-justified mt-5 is-size-6">
        <p> 
          We draw from developmental psychology and introduce <strong>Spelke objects</strong>—groupings of physical entities that reliably move together under applied forces, a concept first established by Liz Spelke in <a href="https://www.harvardlds.org/wp-content/uploads/2017/01/Spelke1990-1.pdf" target="_blank" rel="noopener noreferrer">Principles of Object Perception</a>. 
          Unlike semantic segmentation, Spelke objects are defined by category-agnostic causal motion relationships, making them inherently better suited to support robotics tasks such as manipulation and planning.
        </p>
      </div>

    </div>

    <!-- SEC 2: Benchmarking Spelke Segments -->
    <div class="content">
      <h2 class="has-text-weight-bold is-size-5 mb-4">Benchmarking Spelke segments</h2>

      <!-- Main body paragraph -->
      <div class="content has-text-justified mt-5 is-size-6">
        <p>
          We first benchmark...(why this needs to benchmark, existing datasets )
          To systematically evaluate segmentation models against Spelke object principles, we introduce <strong>SpelkeBench</strong>—a 500-image dataset that measures how well segments align with Spelke objects.
          We curate the dataset from two complementary sources: <a href="http://luqi.info/entityv2.github.io/" target="_blank" rel="noopener noreferrer">EntitySeg</a>, featuring high-resolution internet imagery with dense segmentation annotations, and <a href="https://robotics-transformer-x.github.io/" target="_blank" rel="noopener noreferrer">Open X-Embodiment</a>, consisting of real-world egocentric robot interactions. 
          This contrast enables evaluation across both unconstrained natural image domains and physically grounded robotics environments.
        </p>
      </div>

      <!-- Image with caption -->
      <figure class="image is-inline-block has-text-centered">
        <img src="./static/images/benchmark_comparison.png"
             class="interpolation-image"
             alt="Comparison between datasets."  />
        <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
          <strong>Example Segments from SpelkeBench.</strong> Existing segmentation annotation methods like SAM and EntitySeg frequently contain segments that do not represent units that would intuitively move together in the real world (e.g. camera subcomponents and bottle labels),  
          demonstrating that current benchmarks fail to capture the notion of Spelke segments and limiting their utility for physical reasoning tasks common in robotics. 
          Thus, we introduce SpelkeBench to benchmark the capability of segmentation models to produce segments aligned with Spelke objects.
        </figcaption>
      </figure>
    </div>

    <!-- SEC 3: Operationalizing Spelke Segments -->
    <div class="content">
      <h2 class="has-text-weight-bold is-size-5 mb-4">SpelkeNet: Operationalizing Spelke Segmentation</h2>

      <!-- Subsection 1: Local Random Access Sequence Modeling (LRAS) -->
      <div class="content has-text-justified mt-5 is-size-6">
        <p>
          We build <strong>SpelkeNet</strong>, a model that learns to complete flow fields and implicitly captures how objects move together in the physical world. 
          SpelkeNet is an instance of Local Random Access Sequence Modeling (LRAS), which provides an ideal foundation for this task because unlike diffusion models that require dense global conditioning, LRAS's autoregressive nature makes it simple to append localized interventions.

          Specifically, LRAS is a sequence model trained with next token prediction objective common in LLMs, where the final token sequence includes content tokens representing RGB or flow in arbitrary spatial order. 

          Building on this foundation, <strong>SpelkeNet</strong> capitalizes on LRAS's composable sequence design for Spelke object discovery. 
          Specifically, SpelkeNet applies sparse, localized interventions by simply appending a flow token representing the desired motion—i.e. a <strong>virtual poke</strong>—along with a corresponding pointer token indicating the poke location. 
          SpelkeNet then discovers Spelke objects by completing the remaining token sequence and extracting the completed flow field that reveals how the rest of the scene responds to this intervention.
        </p>
      </div>
      
      <figure class="image is-inline-block has-text-centered">
        <img src="./static/images/spelkenet_architecture.png"
            class="interpolation-image"
            alt="LRAS Architecture" />
        <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
          <strong>SpelkeNet Architecture.</strong> On the <strong>left</strong> we illustrate SpelkeNet—i.e. the LRAS framework applied to optical-flow completion. Each input image and its flow field are tokenized into spatially-indexed RGB and flow tokens. 
          These token pairs are passed as an unordered sequence into the model, which outputs a categorical distribution \( \mathcal{D}[i] \) over flow tokens for each spatial location \( i \). In the <strong>right</strong> panel we show that sampling from these distributions yields a complete flow field in pixel space that we use for discovering co-moving entities/segments.
        </figcaption>
      </figure>

      <!-- Subsection 2: Motion Affordance Maps -->
      <div class="content has-text-justified mt-5 is-size-6">
        <h3 class="has-text-weight-bold is-size-6">Motion Affordance Maps</h3>
        <p>
          To discover Spelke objects, we must first identify which pixels correspond to candidate movable entities within a scene in order to apply meaningful virtual pokes. 
          Motion affordance maps prove especially valuable in robotics applications for identifying high-motion regions independent of camera motion that respond to interaction (e.g. cups or plates) and excluding
          low-motion regions (e.g. sky or ground) which do not typically do not move upon external forces.
          We refer to this notion as the <strong>probability of motion affordance map</strong>, denoted \( p_{\text{motion}} \), which is a structure that we can extract from SpelkeNet.
          To compute \( p_{\text{motion}} \), we sum the predicted flow token distributions at each spatial location for all tokens which represent non-zero motion 
          to yield a 2D heatmap of regions likely to move under external forces.
        </p>
      </div>
      
      <!-- Carousel Container -->
      <div style="margin-top: 1rem; position: relative; max-width: 900px; margin-left: auto; margin-right: auto;">
        
        <!-- Carousel Images Container -->
        <div id="affordance-carousel" style="position: relative; overflow: hidden; border-radius: 8px; background: #f5f5f5;">
          <div id="carousel-images" style="display: flex; transition: transform 0.3s ease-in-out;">
            <img src="./static/images/affordancemap/1.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/2.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/3.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/4.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/5.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/6.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/7.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/8.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
          </div>
        </div>
        
        <!-- Navigation Buttons -->
        <button id="prev-btn" style="position: absolute; left: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">‹</button>
        <button id="next-btn" style="position: absolute; right: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">›</button>
        
        <!-- Image Counter -->
        <div id="image-counter" style="position: absolute; bottom: 10px; right: 10px; background: rgba(0,0,0,0.7); color: white; padding: 4px 8px; border-radius: 12px; font-size: 12px; z-index: 10;">1 / 8</div>
      </div>
      
      <!-- Caption -->
      <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
        <strong>Motion Affordance Maps.</strong> Here we illustrate input images and their corresponding
        probability of motion heatmaps showing regions likely to exhibit motion under externally applied forces.
      </figcaption>
      
      <script>
      (function() {
        let currentIndex = 0;
        const totalImages = 8;
        const imagesPerView = 3;
        const maxIndex = totalImages - imagesPerView; // 5 (positions 0-5)
        const carouselImages = document.getElementById('carousel-images');
        const imageCounter = document.getElementById('image-counter');
        const prevBtn = document.getElementById('prev-btn');
        const nextBtn = document.getElementById('next-btn');
        
        function updateCarousel() {
          const translateX = -currentIndex * (100 / imagesPerView); // Move by 33.333%
          carouselImages.style.transform = `translateX(${translateX}%)`;
          
          const startImage = currentIndex + 1;
          const endImage = Math.min(currentIndex + imagesPerView, totalImages);
          imageCounter.textContent = `${startImage}-${endImage} / ${totalImages}`;
        }
        
        function nextImage() {
          if (currentIndex < maxIndex) {
            currentIndex++;
          } else {
            currentIndex = 0; // Loop back to start
          }
          updateCarousel();
        }
        
        function prevImage() {
          if (currentIndex > 0) {
            currentIndex--;
          } else {
            currentIndex = maxIndex; // Loop to end
          }
          updateCarousel();
        }
        
        nextBtn.addEventListener('click', nextImage);
        prevBtn.addEventListener('click', prevImage);
        
        // Optional: Auto-advance every 5 seconds
        // setInterval(nextImage, 5000);
        
        // Keyboard navigation
        document.addEventListener('keydown', function(e) {
          if (e.key === 'ArrowLeft') prevImage();
          if (e.key === 'ArrowRight') nextImage();
        });
        
        // Initialize
        updateCarousel();
      })();
      </script>

      <!-- Subsection 3: Expected Displacement Maps -->
      <div class="content has-text-justified mt-5 is-size-6">
        <h3 class="has-text-weight-bold is-size-6">Expected Displacement Maps</h3>
        <p>
          Another useful structure extracted from SpelkeNet is the <strong>expected displacement map</strong>, denoted \( \mathbb{E}_{\text{disp}} \), which is an estimate of likely flow at each location conditioned on a virtual poke. 
          This proves especially valuable in robotics applications where understanding the effects of actions before physical contact is crucial. 
          This map provides guidance about how objects might move if interacted with, enabling robots to predict interaction outcomes without executing actions in the physical world. 
          To obtain \( \mathbb{E}_{\text{disp}} \), we apply a virtual poke at a desired location to obtain a predicted distribution, which we then compute as a probability-weighted average over the flow vectors, giving us a dense 2D vector field over spatial locations.
        </p>
      </div>
      
      <!-- Expected Displacement Carousel Container -->
      <div style="margin-top: 1rem; position: relative; max-width: 900px; margin-left: auto; margin-right: auto;">
        
        <!-- Carousel Images Container -->
        <div id="displacement-carousel" style="position: relative; overflow: hidden; border-radius: 8px; background: #f5f5f5;">
          <div id="displacement-carousel-images" style="display: flex; transition: transform 0.3s ease-in-out;">
            <img src="./static/images/expecteddisplacement/ed1.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/expecteddisplacement/ed3.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/expecteddisplacement/ed4.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/expecteddisplacement/ed5.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/expecteddisplacement/ed2.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
          </div>
        </div>
        
        <!-- Navigation Buttons -->
        <button id="displacement-prev-btn" style="position: absolute; left: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">‹</button>
        <button id="displacement-next-btn" style="position: absolute; right: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">›</button>
        
        <!-- Image Counter -->
        <div id="displacement-image-counter" style="position: absolute; bottom: 10px; right: 10px; background: rgba(0,0,0,0.7); color: white; padding: 4px 8px; border-radius: 12px; font-size: 12px; z-index: 10;">1 / 5</div>
      </div>
      
      <!-- Caption -->
      <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
        <strong>Expected Displacement Maps.</strong> Dense vector fields that predict how each pixel in a scene would move in response to a virtual poke applied at a specific location.
      </figcaption>
      
      <script>
      (function() {
        let displacementCurrentIndex = 0;
        const displacementTotalImages = 5;
        const displacementImagesPerView = 3;
        const displacementMaxIndex = displacementTotalImages - displacementImagesPerView; // 3 (positions 0-3)
        const displacementCarouselImages = document.getElementById('displacement-carousel-images');
        const displacementImageCounter = document.getElementById('displacement-image-counter');
        const displacementPrevBtn = document.getElementById('displacement-prev-btn');
        const displacementNextBtn = document.getElementById('displacement-next-btn');
        
        function updateDisplacementCarousel() {
          const translateX = -displacementCurrentIndex * (100 / displacementImagesPerView); // Move by 33.333%
          displacementCarouselImages.style.transform = `translateX(${translateX}%)`;
          
          const startImage = displacementCurrentIndex + 1;
          const endImage = Math.min(displacementCurrentIndex + displacementImagesPerView, displacementTotalImages);
          displacementImageCounter.textContent = `${startImage}-${endImage} / ${displacementTotalImages}`;
        }
        
        function nextDisplacementImage() {
          if (displacementCurrentIndex < displacementMaxIndex) {
            displacementCurrentIndex++;
          } else {
            displacementCurrentIndex = 0; // Loop back to start
          }
          updateDisplacementCarousel();
        }
        
        function prevDisplacementImage() {
          if (displacementCurrentIndex > 0) {
            displacementCurrentIndex--;
          } else {
            displacementCurrentIndex = displacementMaxIndex; // Loop to end
          }
          updateDisplacementCarousel();
        }
        
        displacementNextBtn.addEventListener('click', nextDisplacementImage);
        displacementPrevBtn.addEventListener('click', prevDisplacementImage);
        
        // Initialize
        updateDisplacementCarousel();
      })();
      </script>

      <!-- subsection 4: Spelke Object Discovery Algorithm -->
      <div class="content has-text-justified mt-5 is-size-6">
        <h3 class="has-text-weight-bold is-size-6">Statistical counterfactual probing for Spelke object discovery</h3>
        
        <div class="content has-text-justified mt-5 is-size-6">
          <p>
            We now combine \( p_{\text{motion}} \) and \( \mathbb{E}_{\text{disp}} \) to discover Spelke objects. 
            We first sample a location that is likely to move from \( p_{\text{motion}} \). 
            Then, to discover Spelke objects we will identify regions that consistently move together under various virtual pokes applied at this location.
            For each poke direction, we compute \( \mathbb{E}_{\text{disp}} \). 
            To find pixels that move in coordination with the poke, we average the dot product between each poke vector and the expected motion across all pokes. 
            This statistical aggregation reveals regions which consistently move together across a wide range of applied virtual pokes—further implicitly aligning our discovered objects with the notion of Spelke objects which consistently move together. 
            Finally, Otsu's method on the averaged dot product yields our desired Spelke segment.  
          </p>
        </div>
        
        <!-- Object Discovery Carousel Container -->
        <div style="margin-top: 1rem; position: relative; max-width: 900px; margin-left: auto; margin-right: auto;">
          
          <!-- Carousel Videos Container -->
          <div id="discovery-carousel" style="position: relative; overflow: hidden; border-radius: 8px; background: #f5f5f5;">
            <div id="discovery-carousel-videos" style="display: flex; transition: transform 0.3s ease-in-out;">
              <video autoplay muted loop playsinline style="width: 100%; height: 650px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
                <source src="./static/videos/obj_discovery/2.mov" type="video/mp4">
              </video>
              <video autoplay muted loop playsinline style="width: 100%; height: 650px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
                <source src="./static/videos/obj_discovery/1.mov" type="video/mp4">
              </video>
              <video autoplay muted loop playsinline style="width: 100%; height: 650px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
                <source src="./static/videos/obj_discovery/3.mov" type="video/mp4">
              </video>
            </div>
          </div>
          
          <!-- Navigation Buttons -->
          <button id="discovery-prev-btn" style="position: absolute; left: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">‹</button>
          <button id="discovery-next-btn" style="position: absolute; right: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">›</button>
          
          <!-- Image Counter -->
          <div id="discovery-video-counter" style="position: absolute; bottom: 10px; right: 10px; background: rgba(0,0,0,0.7); color: white; padding: 4px 8px; border-radius: 12px; font-size: 12px; z-index: 10;">1 / 3</div>
        </div>
        
        <!-- Caption -->
        <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
          <strong>Spelke Object Discovery Algorithm.</strong>
          Multiple virtual pokes are applied at locations sampled from the \( p_{\text{motion}} \) map. As shown, this approach can discover multiple objects within a scene and produces more meaningful segments that align with Spelke objects as compared to the SAM segments.
        </figcaption>
        
        <script>
        (function() {
          let discoveryCurrentIndex = 0;
          const discoveryTotalVideos = 3;
          const discoveryVideosPerView = 1;
          const discoveryMaxIndex = discoveryTotalVideos - discoveryVideosPerView; // 2 (positions 0-2)
          const discoveryCarouselVideos = document.getElementById('discovery-carousel-videos');
          const discoveryVideoCounter = document.getElementById('discovery-video-counter');
          const discoveryPrevBtn = document.getElementById('discovery-prev-btn');
          const discoveryNextBtn = document.getElementById('discovery-next-btn');
          
          function updateDiscoveryCarousel() {
            const translateX = -discoveryCurrentIndex * (100 / discoveryVideosPerView); // Move by 100%
            discoveryCarouselVideos.style.transform = `translateX(${translateX}%)`;
            
            const currentVideo = discoveryCurrentIndex + 1;
            discoveryVideoCounter.textContent = `${currentVideo} / ${discoveryTotalVideos}`;
          }
          
          function nextDiscoveryVideo() {
            if (discoveryCurrentIndex < discoveryMaxIndex) {
              discoveryCurrentIndex++;
            } else {
              discoveryCurrentIndex = 0; // Loop back to start
            }
            updateDiscoveryCarousel();
          }
          
          function prevDiscoveryVideo() {
            if (discoveryCurrentIndex > 0) {
              discoveryCurrentIndex--;
            } else {
              discoveryCurrentIndex = discoveryMaxIndex; // Loop to end
            }
            updateDiscoveryCarousel();
          }
          
          discoveryNextBtn.addEventListener('click', nextDiscoveryVideo);
          discoveryPrevBtn.addEventListener('click', prevDiscoveryVideo);
          
          // Initialize
          updateDiscoveryCarousel();
        })();
        </script>

        <h3 class="has-text-weight-bold is-size-6">SpelkeNet achieves state-of-the-art performance on SpelkeBench</h3>
        <div class="content has-text-justified mt-5 is-size-6">
          <p>
            To evaluate our model’s ability to discover Spelke objects, we formalize the
            task as point-promoted segmentation: given a single point on an object, the goal is to predict the Spelke segment associated with that point. 
            We find that SpelkeNet outperforms both self-supervised baselines (DINO, CWM) and the supervised SAM2 model on SpelkeBench.
          </p>
        </div>
        
        <!-- Quantitative Results Table -->
        <div class="content has-text-justified mt-5 is-size-6">
          <table style="margin: 0 auto; border-collapse: collapse; text-align: center;">
            <thead>
              <tr style="border-bottom: 2px solid #000;">
                <th style="padding: 8px 12px;"></th>
                <th style="padding: 8px 12px;"><a href="https://ai.meta.com/sam2/" target="_blank" rel="noopener noreferrer">SAM2</a></th>
                <th style="padding: 8px 12px;"><a href="https://github.com/facebookresearch/dino" target="_blank" rel="noopener noreferrer">DINOv1-B/8</a></th> 
                <th style="padding: 8px 12px;"><a href="https://dinov2.metademolab.com/" target="_blank" rel="noopener noreferrer">DINOv2-L/14</a></th> 
                <th style="padding: 8px 12px;"><a href="https://dinov2.metademolab.com/" target="_blank" rel="noopener noreferrer">DINOv2-G/14</a></th>
                <th style="padding: 8px 12px;"><a href="https://neuroailab.github.io/cwm-physics/" target="_blank" rel="noopener noreferrer">CWM</a></th>
                <th style="padding: 8px 12px;">SpelkeNet</th>
              </tr>
            </thead>
            <tbody>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px 12px; text-align: left;">AR</td>
                <td style="padding: 8px 12px;">0.4816</td>
                <td style="padding: 8px 12px;">0.2708</td>
                <td style="padding: 8px 12px;">0.2524</td>
                <td style="padding: 8px 12px;">0.2254</td>
                <td style="padding: 8px 12px;">0.3271</td>
                <td style="padding: 8px 12px; font-weight: bold;">0.5411</td>
              </tr>
              <tr style="border-bottom: 2px solid #000;">
                <td style="padding: 8px 12px; text-align: left;">mIoU</td>
                <td style="padding: 8px 12px;">0.6225</td>
                <td style="padding: 8px 12px;">0.4990</td>
                <td style="padding: 8px 12px;">0.4931</td>
                <td style="padding: 8px 12px;">0.4553</td>
                <td style="padding: 8px 12px;">0.4807</td>
                <td style="padding: 8px 12px; font-weight: bold;">0.6811</td>
              </tr>
            </tbody>
            <thead>
          </table>
          <caption class="is-size-6 has-text-grey mt-4" style="margin-bottom: 1rem; font-style: italic; text-align:justify">
            <strong>Evaluation of point-prompted segmentation accuracy.</strong> 
            We report Average Recall (AR) and mean Intersection over Union (mIoU) for various segmentation methods.
          </caption>
        </div>
      </div>
    </div>

    <!-- SEC 4: Using Spelke Segments for Physically Plausible Object Manipulation -->
    <div class="content">
      <h2 class="has-text-weight-bold is-size-5 mb-4">Using Spelke segments for physically plausible object manipulation</h2>
      
      <div class="content has-text-justified mt-5 is-size-6">
        <p>
          In object-centric scene editing tasks, where users provide edit prompts for 2D or 3D transformations, segmentation plays a crucial role in creating edit masks from user prompts, 
          making mask quality important for realistic results.
          For physically plausible scene edits, masks must reflect genuinely movable entities rather than arbitrary visual boundaries.
          As such, Spelke segments prove particularly valuable for this application, yielding more realistic scene edits as we demonstrate in our experiments with SpelkeNet.
        </p>
      </div>
      
      <!-- Object Manipulation Carousel Container -->
      <div style="margin-top: 1rem; position: relative; max-width: 900px; margin-left: auto; margin-right: auto;">
        
        <!-- Carousel Videos Container -->
        <div id="manipulation-carousel" style="position: relative; overflow: hidden; border-radius: 8px; background: #f5f5f5;">
          <div id="manipulation-carousel-images" style="display: flex; transition: transform 0.3s ease-in-out;">
            <video autoplay muted loop playsinline style="width: 100%; height: 500px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
              <source src="./static/videos/objmanipulation/3.mov" type="video/mp4">
            </video>
            <video autoplay muted loop playsinline style="width: 100%; height: 500px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
              <source src="./static/videos/objmanipulation/2.mov" type="video/mp4">
            </video>
            <video autoplay muted loop playsinline style="width: 100%; height: 500px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
              <source src="./static/videos/objmanipulation/1.mov" type="video/mp4">
            </video>
          </div>
        </div>
        
        <!-- Navigation Buttons -->
        <button id="manipulation-prev-btn" style="position: absolute; left: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">‹</button>
        <button id="manipulation-next-btn" style="position: absolute; right: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">›</button>
        
        <!-- Image Counter -->
        <div id="manipulation-image-counter" style="position: absolute; bottom: 10px; right: 10px; background: rgba(0,0,0,0.7); color: white; padding: 4px 8px; border-radius: 12px; font-size: 12px; z-index: 10;">1 / 3</div>
      </div>
      
      <!-- Caption -->
      <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
        <strong>Comparison of SpelkeNet and SAM in Object Manipulation Pipeline.</strong> 
        From a single-point segmentation prompt, the generated segment and edit prompt is used as input to  <a href="https://neuroailab.github.io/projects/lras_3d/" target="_blank" rel="noopener noreferrer">LRAS</a>, a state-of-the-art 3D object manipulation image editing method.
        We show that SpelkeNet segments enable more physically plausible object editing as opposed to existing segmentation methods like SAM, which often split up or combine objects in ways that are inconsistent with how they move.
      </figcaption>
      
      <script>
      (function() {
        let manipulationCurrentIndex = 0;
        const manipulationTotalImages = 3;
        const manipulationImagesPerView = 1;
        const manipulationMaxIndex = manipulationTotalImages - manipulationImagesPerView; // 2 (positions 0-2)
        const manipulationCarouselImages = document.getElementById('manipulation-carousel-images');
        const manipulationImageCounter = document.getElementById('manipulation-image-counter');
        const manipulationPrevBtn = document.getElementById('manipulation-prev-btn');
        const manipulationNextBtn = document.getElementById('manipulation-next-btn');
        
        function updateManipulationCarousel() {
          const translateX = -manipulationCurrentIndex * (100 / manipulationImagesPerView); // Move by 100%
          manipulationCarouselImages.style.transform = `translateX(${translateX}%)`;
          
          const currentImage = manipulationCurrentIndex + 1;
          manipulationImageCounter.textContent = `${currentImage} / ${manipulationTotalImages}`;
        }
        
        function nextManipulationImage() {
          if (manipulationCurrentIndex < manipulationMaxIndex) {
            manipulationCurrentIndex++;
          } else {
            manipulationCurrentIndex = 0; // Loop back to start
          }
          updateManipulationCarousel();
        }
        
        function prevManipulationImage() {
          if (manipulationCurrentIndex > 0) {
            manipulationCurrentIndex--;
          } else {
            manipulationCurrentIndex = manipulationMaxIndex; // Loop to end
          }
          updateManipulationCarousel();
        }
        
        manipulationNextBtn.addEventListener('click', nextManipulationImage);
        manipulationPrevBtn.addEventListener('click', prevManipulationImage);
        
        // Initialize
        updateManipulationCarousel();
      })();
      </script>


      <h3 class="has-text-weight-bold is-size-6">Across various object manipulation pipelines, Spelke segments yield more physically plausible object edits</h3>
      <div class="content has-text-justified mt-5 is-size-6">
        <p>
          To evaluate the utility of SpelkeNet segments for object manipulation, we replace SAM with SpelkeNet in the pipeline for existing object editing models.
          Specifically, we use <a href="https://neuroailab.github.io/projects/lras_3d/" target="_blank" rel="noopener noreferrer"><strong>3DEditBench</strong></a>, a benchmark containing 100 image pairs with associated ground truth point prompts and 3D scene edits (e.g. rotations, translations). 
          From the table below, we show that for existing object manipulation methods, SpelkeNet segments improve performance significantly.
        </p>
      </div>

      <div class="content has-text-justified mt-5 is-size-6">
        <table style="margin: 0 auto; border-collapse: collapse; text-align: center;">
          <thead>
            <tr style="border-bottom: 2px solid #000;">
              <th style="padding: 8px 12px;">Method</th>
              <th style="padding: 8px 12px;">Segment</th>
              <th style="padding: 8px 12px;">MSE ↓</th>
              <th style="padding: 8px 12px;">PSNR ↑</th>
              <th style="padding: 8px 12px;">LPIPS ↓</th>
              <th style="padding: 8px 12px;">SSIM ↑</th>
              <th style="padding: 8px 12px;">EA ↑</th>
            </tr>
          </thead>
          <tbody>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px; text-align: left;" rowspan="2"><a href="https://neuroailab.github.io/projects/lras_3d/" target="_blank" rel="noopener noreferrer">LRAS</a></td>
              <td style="padding: 8px 12px;">SpelkeNet</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.009</td>
              <td style="padding: 8px 12px; font-weight: bold;">21.64</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.213</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.698</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.776</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px;">SAM</td>
              <td style="padding: 8px 12px;">0.013</td>
              <td style="padding: 8px 12px;">20.17</td>
              <td style="padding: 8px 12px;">0.255</td>
              <td style="padding: 8px 12px;">0.685</td>
              <td style="padding: 8px 12px;">0.633</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px; text-align: left;" rowspan="2"><a href="https://lightning-drag.github.io/" target="_blank" rel="noopener noreferrer">LightningDrag</a></td>
              <td style="padding: 8px 12px;">SpelkeNet</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.017</td>
              <td style="padding: 8px 12px; font-weight: bold;">19.16</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.195</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.672</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.679</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px;">SAM</td>
              <td style="padding: 8px 12px;">0.020</td>
              <td style="padding: 8px 12px;">18.18</td>
              <td style="padding: 8px 12px;">0.241</td>
              <td style="padding: 8px 12px;">0.658</td>
              <td style="padding: 8px 12px;">0.536</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px; text-align: left;" rowspan="2"><a href="https://diffusionhandles.github.io/" target="_blank" rel="noopener noreferrer">Diffusion Handles</a></td>
              <td style="padding: 8px 12px;">SpelkeNet</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.024</td>
              <td style="padding: 8px 12px; font-weight: bold;">17.42</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.364</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.555</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.576</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px;">SAM</td>
              <td style="padding: 8px 12px;">0.031</td>
              <td style="padding: 8px 12px;">16.15</td>
              <td style="padding: 8px 12px;">0.419</td>
              <td style="padding: 8px 12px;">0.526</td>
              <td style="padding: 8px 12px;">0.495</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px; text-align: left;" rowspan="2"><a href="https://igl-hkust.github.io/das/" target="_blank" rel="noopener noreferrer">Diffusion as Shader</a></td>
              <td style="padding: 8px 12px;">SpelkeNet</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.015</td>
              <td style="padding: 8px 12px; font-weight: bold;">19.29</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.194</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.707</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.640</td>
            </tr>
            <tr style="border-bottom: 2px solid #000;">
              <td style="padding: 8px 12px;">SAM</td>
              <td style="padding: 8px 12px;">0.019</td>
              <td style="padding: 8px 12px;">18.20</td>
              <td style="padding: 8px 12px;">0.253</td>
              <td style="padding: 8px 12px;">0.682</td>
              <td style="padding: 8px 12px;">0.503</td>
            </tr>
          </tbody>
        </table>
        <caption class="is-size-6 has-text-grey mt-4" style="margin-bottom: 1rem; font-style: italic; text-align:justify">
          <strong>Evaluation of edit quality across segmentation methods and editing pipelines.</strong> We report results for edits generated using SAM versus SpelkeNet segments across four editing models. Lower ↓ is better, higher ↑ is better.
        </caption>
      </div>
    </div>

    <!-- SEC 5: Emergent Properties -->
    <div class="content">
      <h2 class="has-text-weight-bold is-size-5 mb-4">Emergent Properties of SpelkeNet</h2>
      
      <div class="content has-text-justified mt-5 is-size-6">
        <p>
          We have demonstrated SpelkeNet's utility in discovering Spelke segments and shown how these segments enable more realistic scene edits in object manipulation pipelines. 
          Beyond these applications, SpelkeNet also exhibits emergent properties that reveal a deeper understanding of physical scene structure.
        </p>
      </div>

      <!-- Subsection 1: Material Property Understanding -->
      <div class="content has-text-justified mt-5 is-size-6">
        
        <figure class="image is-inline-block has-text-centered">
          <img src="./static/images/material.png" alt="Material Understanding" style="height: 500px; object-fit: contain; max-width: 100%;">
          <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
            <strong>Material Property Understanding.</strong> The generated \( p_{\text{motion}} \) maps can be used to infer physical attributes such as rigidity or material type.
            Rigid objects like laptops and cardboard boxes tend to exhibit a
          uniform probability across the segment, while deformable objects such as cloth and plastic covers
          often show more localized motion responses near the poke point.
          </figcaption>
        </figure>
      </div>

      <!-- Subsection 2: Understanding Support Relationships -->
      <div class="content has-text-justified mt-5 is-size-6">
        <figure class="image is-inline-block has-text-centered">
          <img src="./static/images/supp_relationships.png" alt="Support Relationships" style="height: 500px; object-fit: contain; max-width: 100%;">
          <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
            <strong>Support Relationships Understanding.</strong> When applying a virtual poke to an object within a stack (e.g. the bottom book), the extracted Spelke segment includes both the poked object and all the objects it physically supports, implying an understanding of support hierarchies within a scene.
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{venkatesh2025discoveringandusingsegments,
  title        = {Discovering and using Spelke segments}, 
  author       = {Rahul Venkatesh and Klemen Kotar and Lilian Naing Chen and Seoungwoo Kim and Luca Thomas Wheeler and Jared Watrous and Ashley Xu and Gia Ancone and Wanhee Lee and Honglin Chen and Daniel Bear and Stefan Stojanov and Daniel Yamins},
  year         = {2025},
  eprint       = {TODO},
  archivePrefix = {arXiv},
  primaryClass = {cs.CV},
  url          = {TODO}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>