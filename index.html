<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Discovering and using Spelke segments">
  <meta name="keywords" content="Segmentation, Computer Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Discovering and using Spelke segments</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/website_logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Discovering and using Spelke segments</h1>

          <!-- Smaller font size applied here -->
          <div style="font-size: 0.85rem;">
            <div class="is-size-6 publication-authors">
              <div>
              <span class="author-block">
                <a href="https://rahulvenkk.github.io/" target="_blank" rel="noopener noreferrer">Rahul Venkatesh</a><sup>*1</sup>,
              <span class="author-block">
                <a href="https://klemenkotar.github.io/" target="_blank" rel="noopener noreferrer">Klemen Kotar</a><sup>*1</sup>,
              <span class="author-block">
                <a href="https://www.linkedin.com/in/lilian-chen-1975b81b1/" target="_blank" rel="noopener noreferrer">Lilian Naing Chen</a><sup>*1</sup>,
              <span class="author-block">
                <a href="https://www.linkedin.com/in/seungwoo-simon-kim/" target="_blank" rel="noopener noreferrer">Seungwoo Kim</a><sup>1</sup>,
              <span class="author-block">
                <a href="https://www.linkedin.com/in/luca-wheeler-180818244/" target="_blank" rel="noopener noreferrer">Luca Thomas Wheeler</a><sup>1</sup>,
              <span class="author-block">
                <a href="https://www.linkedin.com/in/jared-watrous/" target="_blank" rel="noopener noreferrer">Jared Watrous</a><sup>1</sup>,
              </div>
              <div>
                <span class="author-block">
                <a href="https://www.linkedin.com/in/ashley-xu-a2588b1a9/" target="_blank" rel="noopener noreferrer">Ashley Xu</a><sup>1</sup>,
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/gia-ancone-58b545207/" target="_blank" rel="noopener noreferrer">Gia Ancone</a><sup>1</sup>,
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/wanhee-lee-31102820b/" target="_blank" rel="noopener noreferrer">Wanhee Lee</a><sup>1</sup>,
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/honglin-chen-52b13712a/" target="_blank" rel="noopener noreferrer">Honglin Chen</a><sup>2</sup>,
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/daniel-bear-b79480279/" target="_blank" rel="noopener noreferrer">Daniel Bear</a><sup>3</sup>,
                <span class="author-block">
                  <a href="https://sstojanov.github.io/" target="_blank" rel="noopener noreferrer">Stefan Stojanov</a><sup>1</sup>,
                <span class="author-block">
                  <a href="https://web.stanford.edu/~yamins/" target="_blank" rel="noopener noreferrer">Daniel Yamins</a><sup>1</sup>

              </div>
            </div>

            <div class="is-size-6 publication-authors" style="margin-top: 0.5em;">
              <span class="author-block"><sup>1</sup>Stanford University,</span>
              <span class="author-block"><sup>2</sup>OpenAI,</span>
              <span class="author-block"><sup>3</sup>Noetik Inc.</span>
            </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://neuroailab.github.io/spelke_net/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://neuroailab.github.io/spelke_net/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://neuroailab.github.io/spelke_net/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://neuroailab.github.io/spelke_net/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  #teaser {
    width: 100%;
    height: auto;
    display: block;
    border-radius: 8px;
  }
  
  /* Custom video controls styling */
  .video-controls {
    margin-top: 1rem;
    display: flex;
    align-items: center;
    gap: 1rem;
    padding: 0.5rem;
    background: rgba(0, 0, 0, 0.05);
    border-radius: 8px;
  }
  
  .play-pause-btn {
    background: #333;
    color: white;
    border: none;
    border-radius: 50%;
    width: 40px;
    height: 40px;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 12px;
    transition: background 0.2s;
  }
  
  .play-pause-btn:hover {
    background: #555;
  }
  
  .scrubber-container {
    flex: 1;
    position: relative;
  }
  
  .scrubber {
    width: 100%;
    height: 4px;
    border-radius: 2px;
    background: #ddd;
    outline: none;
    cursor: pointer;
    -webkit-appearance: none;
    appearance: none;
  }
  
  .scrubber::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 12px;
    height: 12px;
    border-radius: 50%;
    background: #333;
    cursor: pointer;
    transition: transform 0.2s;
  }
  
  .scrubber::-webkit-slider-thumb:hover {
    transform: scale(1.2);
  }
  
  .scrubber::-moz-range-thumb {
    width: 12px;
    height: 12px;
    border-radius: 50%;
    background: #333;
    cursor: pointer;
    border: none;
    transition: transform 0.2s;
  }
  
  .scrubber::-moz-range-thumb:hover {
    transform: scale(1.2);
  }
  
  .time-display {
    color: #666;
    font-size: 14px;
    font-family: monospace;
    white-space: nowrap;
  }
  
  .progress-bar {
    position: absolute;
    top: 0;
    left: 0;
    height: 4px;
    background: #333;
    border-radius: 2px;
    pointer-events: none;
    transition: width 0.1s;
  }
</style>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline>
        <source src="./static/videos/teaser_vid.mov"
                type="video/mp4">
      </video>
      
      <div class="video-controls">
        <button class="play-pause-btn" id="playPauseBtn">❚❚</button>
        
        <div class="scrubber-container">
          <div class="progress-bar" id="progressBar"></div>
          <input type="range" class="scrubber" id="scrubber" min="0" max="100" value="0">
        </div>
        
        <div class="time-display">
          <span id="currentTime">0:00</span> / <span id="duration">0:00</span>
        </div>
      </div>
      
      <h2 class="subtitle 6 has-text-grey mt-4" style="font-style: italic; text-align:justify">
        <strong>Overview of SpelkeNet's capabilities.</strong> 
        On the <strong>left</strong>, our model first predicts a probability of motion map, indicating regions likely to move if an external force is applied. 
        We sample a point from this map, apply a virtual poke, and have the model complete a flow field revealing which other pixels will move as a result of this poke. From this,
        we can naturally extract a group of pixels which move together—i.e. a Spelke segment.
        On the <strong>right</strong>, we illustrate how these discovered segments can enable more physically plausible object manipulation as compared to SAM.
      </h2>
    </div>
  </div>
</section>

<script>
  document.addEventListener('DOMContentLoaded', function() {
    const video = document.getElementById('teaser');
    const playPauseBtn = document.getElementById('playPauseBtn');
    const scrubber = document.getElementById('scrubber');
    const progressBar = document.getElementById('progressBar');
    const currentTimeSpan = document.getElementById('currentTime');
    const durationSpan = document.getElementById('duration');
    
    let isDragging = false;
    
    // Format time helper with better error handling
    function formatTime(seconds) {
      if (isNaN(seconds) || !isFinite(seconds)) {
        return '0:00';
      }
      const mins = Math.floor(seconds / 60);
      const secs = Math.floor(seconds % 60);
      return `${mins}:${secs.toString().padStart(2, '0')}`;
    }
    
    // Initialize controls when video metadata is ready
    function initializeControls() {
      if (video.duration && isFinite(video.duration)) {
        durationSpan.textContent = formatTime(video.duration);
        scrubber.max = 100; // Use percentage instead of seconds
        scrubber.value = 0;
        progressBar.style.width = '0%';
        currentTimeSpan.textContent = formatTime(0);
      }
    }
    
    // Update duration when metadata loads
    video.addEventListener('loadedmetadata', initializeControls);
    
    // Also try to initialize if metadata is already loaded
    if (video.readyState >= 1) {
      initializeControls();
    }
    
    // Update scrubber and time as video plays
    video.addEventListener('timeupdate', () => {
      if (!isDragging && video.duration && isFinite(video.duration)) {
        const percentage = (video.currentTime / video.duration) * 100;
        scrubber.value = percentage;
        progressBar.style.width = percentage + '%';
        currentTimeSpan.textContent = formatTime(video.currentTime);
      }
    });
    
    // Play/pause functionality
    playPauseBtn.addEventListener('click', () => {
      if (video.paused) {
        video.play();
        playPauseBtn.textContent = '❚❚';
      } else {
        video.pause();
        playPauseBtn.textContent = '▶';
      }
    });
    
    // Scrubber functionality - convert percentage back to time
    scrubber.addEventListener('input', () => {
      if (video.duration && isFinite(video.duration)) {
        const percentage = scrubber.value;
        const newTime = (percentage / 100) * video.duration;
        progressBar.style.width = percentage + '%';
        currentTimeSpan.textContent = formatTime(newTime);
        // Update video in real-time while dragging
        video.currentTime = newTime;
      }
    });
    
    scrubber.addEventListener('mousedown', () => {
      isDragging = true;
    });
    
    scrubber.addEventListener('mouseup', () => {
      isDragging = false;
      if (video.duration && isFinite(video.duration)) {
        const percentage = scrubber.value;
        video.currentTime = (percentage / 100) * video.duration;
      }
    });
    
    scrubber.addEventListener('change', () => {
      isDragging = false;
      if (video.duration && isFinite(video.duration)) {
        const percentage = scrubber.value;
        video.currentTime = (percentage / 100) * video.duration;
      }
    });
    
    // Handle video play/pause on click
    video.addEventListener('click', () => {
      playPauseBtn.click();
    });
    
    // Update play button state when video ends
    video.addEventListener('ended', () => {
      playPauseBtn.textContent = '▶';
    });
  });
</script>

</body>

<section class="section" style="padding-top: 1rem;">
  <div class="container is-max-desktop">
    <!-- SEC 1.1: Limitations -->
    <div class="content">
      <h2 class="has-text-weight-bold is-size-4 mb-4">Existing definitions of segmentation may not be sufficient for physical reasoning tasks</h2>

      <!-- Main body paragraph -->
      <div class="content has-text-justified mt-5 is-size-6">
        <p>
          An ongoing challenge in image segmentation is defining segments with arbitrary categories, 
          as existing segmentation datasets like <a href="https://cocodataset.org/#home" target="_blank" rel="noopener noreferrer">COCO</a> and <a href="https://ade20k.csail.mit.edu/" target="_blank" rel="noopener noreferrer">ADE20K</a> 
          rely on semantic labels (e.g. car, tree, sky) to define segments.
          Although these are useful for recognition tasks, the resulting masks often do not reflect how objects move or interact in the real world, 
          effectively limiting their utility in robotics tasks like object manipulation, which require physical reasoning capabilities to understand which parts of a scene move together.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section" style="padding-top: 1.75rem;">
  <div class="container is-max-desktop">
    <!-- SEC 1.2: Defining Spelke Objects -->
    <div class="content">
      <h2 class="has-text-weight-bold is-size-4 mb-4">Spelke segments, segments defined based on motion correlation, could help address this limitation</h2>

      <!-- Main body paragraph -->
      <div class="content has-text-justified mt-5 is-size-6">
        <p> 
          We draw from developmental psychology the notion of <strong>Spelke objects</strong>—groupings of physical entities that reliably move together under applied forces, a concept first established by Liz Spelke in <a href="https://www.harvardlds.org/wp-content/uploads/2017/01/Spelke1990-1.pdf" target="_blank" rel="noopener noreferrer">Principles of Object Perception</a>. 
          Unlike semantic segmentation, Spelke objects are defined by category-agnostic causal motion relationships, making them inherently better suited to support robotics tasks such as manipulation and planning.
        </p>
      </div>

    </div>

  </div>
</section>

<!-- SEC 2: Benchmarking Spelke Segments -->
<section class="section" style="padding-top: 1.75rem;">
  <div class="container is-max-desktop">
    <div class="content">
      <h2 class="has-text-weight-bold is-size-4 mb-4">Benchmarking Spelke segments</h2>

      <!-- Main body paragraph -->
      <div class="content has-text-justified mt-5 is-size-6">
        <p>

          We first benchmark the Spelke segment concept by introducing <strong>SpelkeBench</strong>: a 500-image evaluation dataset
          designed to assess whether segmentation algorithms can identify Spelke segments.

          As shown below, existing segmentation annotation methods like SAM and EntitySeg frequently contain segments that do not represent units that would intuitively move together in the real world (e.g. camera subcomponents and bottle labels), demonstrating that current benchmarks fail to capture the notion of Spelke segments.

          We curate the dataset from two complementary sources: <a href="http://luqi.info/entityv2.github.io/" target="_blank" rel="noopener noreferrer">EntitySeg</a>, featuring high-resolution internet imagery with dense segmentation annotations, and <a href="https://robotics-transformer-x.github.io/" target="_blank" rel="noopener noreferrer">Open X-Embodiment</a>, consisting of real-world egocentric robot interactions. 
          This contrast enables evaluation across both unconstrained natural image domains and physically grounded robotics environments.
        </p>
      </div>

      <!-- Image with caption -->
      <figure class="image is-inline-block has-text-centered">
        <img src="./static/images/benchmark_comparison.png"
             class="interpolation-image"
             alt="Comparison between datasets."  />
        <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
          <strong>Example segments from SpelkeBench. </strong> We compare this with SAM and EntitySeg segments to show that SpelkeBench contains annotated segments which align more with the Spelke notion.
        </figcaption>
      </figure>
    </div>
  </div>
</section>

<!-- SEC 3: Operationalizing Spelke Segments -->
<section class="section" style="padding-top: 1.75rem;">
  <div class="container is-max-desktop">
    <div class="content">
      <h2 class="has-text-weight-bold is-size-4 mb-4">SpelkeNet: Operationalizing Spelke Segmentation</h2>

      <!-- Subsection 1: Local Random Access Sequence Modeling (LRAS) -->
      <div class="content has-text-justified mt-5 is-size-6">
        <p>
          We build <strong>SpelkeNet</strong>, a model that learns to complete flow fields and implicitly captures how objects move together in the physical world. 
          SpelkeNet is an instance of <a href="https://neuroailab.github.io/projects/lras_3d/" target="_blank" rel="noopener noreferrer">Local Random Access Sequence Modeling</a> (LRAS), sequence modeling framework
          inspired by LLMs that causally predicts locally quantized image (i.e. RGB) and optical flow patches.
          By leveraging LRAS's sequence design for Spelke object discovery by simply appending a flow token representing the desired motion—i.e. a <strong>virtual poke</strong>—along with a corresponding pointer token indicating the poke location, 
          SpelkeNet can discover Spelke objects by completing the remaining token sequence and extracting the completed flow field that reveals how the rest of the scene responds to this intervention.
          LRAS thus provides an ideal foundation for this task because unlike diffusion models that require dense global conditioning, LRAS's autoregressive nature makes it simple to append sparse, localized interventions.
        </p>
      </div>
      
      <figure class="image is-inline-block has-text-centered">
        <img src="./static/images/spelkenet_architecture.png"
            class="interpolation-image"
            alt="LRAS Architecture" />
        <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
          <strong>SpelkeNet architecture.</strong> On the <strong>left</strong> we illustrate SpelkeNet—an instance of the LRAS framework applied to optical-flow completion. 
          The input is a tokenized RGB image and a sparse <em>virtual poke</em>, with each token being paired with a pointer token indictating spatial location. 
          The model predicts a categorical distribution <em>D</em>[<em>i<sub>j</sub></em>] over flow tokens for every spatial location. 
          The <strong>right</strong> panel shows autoregressive sampling yielding a complete flow field—at each step we select an undecoded location, sample a flow token from the predicted distribution, and append it to the input sequence to be fed back into the model to generate a new distribution. 
          This process repeats, progressively completing the flow field and representing how the scene responds to the virtual poke, enabling Spelke segment discovery through motion correlation analysis of the resulting flow fields.
        </figcaption>
      </figure>
    </div>
  </div>
</section>

<!-- SEC 4: LRAS Structure Extractions -->
<section class="section" style="padding-top: 1.75rem;">
  <div class="container is-max-desktop">
    <div class="content">
      <h2 class="has-text-weight-bold is-size-4 mb-4">Two key structures from LRAS help to discover Spelke objects</h2>
      
      <!-- Subsection 1: Motion Affordance Maps -->
      <div class="content has-text-justified mt-5 is-size-6" style="margin-top: 3rem;">
        <p>
          <strong>Motion affordance maps. </strong> To discover Spelke objects, we must first identify which pixels correspond to candidate movable entities within a scene in order to apply meaningful virtual pokes. 
          Motion affordance maps prove especially valuable in robotics applications for identifying high-motion regions independent of camera motion that respond to interaction (e.g. cups or plates) and excluding
          low-motion regions (e.g. sky or ground) which do not typically do not move upon external forces.
          We refer to this notion as the <strong>probability of motion affordance map</strong>, denoted \( p_{\text{motion}} \), which is a structure that we can extract from SpelkeNet.
          To compute \( p_{\text{motion}} \), we sum the predicted flow token distributions at each spatial location for all tokens which represent non-zero motion 
          to yield a 2D heatmap of regions likely to move under external forces.
        </p>
      </div>
      
      <!-- Carousel Container -->
      <div style="margin-top: 1rem; position: relative; max-width: 900px; margin-left: auto; margin-right: auto;">
        
        <!-- Carousel Images Container -->
        <div id="affordance-carousel" style="position: relative; overflow: hidden; border-radius: 8px; background: #f5f5f5;">
          <div id="carousel-images" style="display: flex; transition: transform 0.3s ease-in-out;">
            <img src="./static/images/affordancemap/1.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/2.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/3.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/4.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/5.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/6.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/7.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/affordancemap/8.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
          </div>
        </div>
        
        <!-- Navigation Buttons -->
        <button id="prev-btn" style="position: absolute; left: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">‹</button>
        <button id="next-btn" style="position: absolute; right: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">›</button>
        
        <!-- Image Counter -->
        <div id="image-counter" style="position: absolute; bottom: 10px; right: 10px; background: rgba(0,0,0,0.7); color: white; padding: 4px 8px; border-radius: 12px; font-size: 12px; z-index: 10;">1 / 8</div>
      </div>
      
      <!-- Caption -->
      <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
        <strong>Motion affordance maps.</strong> Here we illustrate input images and their corresponding
        probability of motion heatmaps showing regions likely to exhibit motion under externally applied forces.
      </figcaption>
      
      <script>
      (function() {
        let currentIndex = 0;
        const totalImages = 8;
        const imagesPerView = 3;
        const maxIndex = totalImages - imagesPerView; // 5 (positions 0-5)
        const carouselImages = document.getElementById('carousel-images');
        const imageCounter = document.getElementById('image-counter');
        const prevBtn = document.getElementById('prev-btn');
        const nextBtn = document.getElementById('next-btn');
        
        function updateCarousel() {
          const translateX = -currentIndex * (100 / imagesPerView); // Move by 33.333%
          carouselImages.style.transform = `translateX(${translateX}%)`;
          
          const startImage = currentIndex + 1;
          const endImage = Math.min(currentIndex + imagesPerView, totalImages);
          imageCounter.textContent = `${startImage}-${endImage} / ${totalImages}`;
        }
        
        function nextImage() {
          if (currentIndex < maxIndex) {
            currentIndex++;
          } else {
            currentIndex = 0; // Loop back to start
          }
          updateCarousel();
        }
        
        function prevImage() {
          if (currentIndex > 0) {
            currentIndex--;
          } else {
            currentIndex = maxIndex; // Loop to end
          }
          updateCarousel();
        }
        
        nextBtn.addEventListener('click', nextImage);
        prevBtn.addEventListener('click', prevImage);
        
        // Optional: Auto-advance every 5 seconds
        // setInterval(nextImage, 5000);
        
        // Keyboard navigation
        document.addEventListener('keydown', function(e) {
          if (e.key === 'ArrowLeft') prevImage();
          if (e.key === 'ArrowRight') nextImage();
        });
        
        // Initialize
        updateCarousel();
      })();
      </script>

      <!-- Subsection 2: Expected Displacement Maps -->
      <div class="content has-text-justified mt-5 is-size-6" style="margin-top: 3rem;">
        <p>
          <strong>Expected displacement maps.</strong> Once we apply a virtual poke at a suitable location, we obtain obtain a predicted distribution, which we then compute as a probability-weighted average over the flow vectors, giving us a dense 2D vector field over spatial locations.
          We call this the <strong>expected displacement map</strong>, denoted \( \mathbb{E}_{\text{disp}} \), which is an estimate of likely flow at each location conditioned on a virtual poke. 
          This map provides guidance about how objects might move if interacted with, enabling robots to predict interaction outcomes without executing actions in the physical world. 
          This proves especially valuable in robotics applications where understanding the effects of actions before physical contact is crucial. 
        </p>
      </div>
      
      <!-- Expected Displacement Carousel Container -->
      <div style="margin-top: 1rem; position: relative; max-width: 900px; margin-left: auto; margin-right: auto;">
        
        <!-- Carousel Images Container -->
        <div id="displacement-carousel" style="position: relative; overflow: hidden; border-radius: 8px; background: #f5f5f5;">
          <div id="displacement-carousel-images" style="display: flex; transition: transform 0.3s ease-in-out;">
            <img src="./static/images/expecteddisplacement/ed1.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/expecteddisplacement/ed3.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/expecteddisplacement/ed4.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/expecteddisplacement/ed5.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
            <img src="./static/images/expecteddisplacement/ed2.png" style="width: 33.333%; height: 600px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
          </div>
        </div>
        
        <!-- Navigation Buttons -->
        <button id="displacement-prev-btn" style="position: absolute; left: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">‹</button>
        <button id="displacement-next-btn" style="position: absolute; right: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">›</button>
        
        <!-- Image Counter -->
        <div id="displacement-image-counter" style="position: absolute; bottom: 10px; right: 10px; background: rgba(0,0,0,0.7); color: white; padding: 4px 8px; border-radius: 12px; font-size: 12px; z-index: 10;">1 / 5</div>
      </div>
      
      <!-- Caption -->
      <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
        <strong>Expected displacement maps.</strong> Dense vector fields that predict how each pixel in a scene would move in response to a virtual poke applied at a specific location.
      </figcaption>
      
      <script>
      (function() {
        let displacementCurrentIndex = 0;
        const displacementTotalImages = 5;
        const displacementImagesPerView = 3;
        const displacementMaxIndex = displacementTotalImages - displacementImagesPerView; // 3 (positions 0-3)
        const displacementCarouselImages = document.getElementById('displacement-carousel-images');
        const displacementImageCounter = document.getElementById('displacement-image-counter');
        const displacementPrevBtn = document.getElementById('displacement-prev-btn');
        const displacementNextBtn = document.getElementById('displacement-next-btn');
        
        function updateDisplacementCarousel() {
          const translateX = -displacementCurrentIndex * (100 / displacementImagesPerView); // Move by 33.333%
          displacementCarouselImages.style.transform = `translateX(${translateX}%)`;
          
          const startImage = displacementCurrentIndex + 1;
          const endImage = Math.min(displacementCurrentIndex + displacementImagesPerView, displacementTotalImages);
          displacementImageCounter.textContent = `${startImage}-${endImage} / ${displacementTotalImages}`;
        }
        
        function nextDisplacementImage() {
          if (displacementCurrentIndex < displacementMaxIndex) {
            displacementCurrentIndex++;
          } else {
            displacementCurrentIndex = 0; // Loop back to start
          }
          updateDisplacementCarousel();
        }
        
        function prevDisplacementImage() {
          if (displacementCurrentIndex > 0) {
            displacementCurrentIndex--;
          } else {
            displacementCurrentIndex = displacementMaxIndex; // Loop to end
          }
          updateDisplacementCarousel();
        }
        
        displacementNextBtn.addEventListener('click', nextDisplacementImage);
        displacementPrevBtn.addEventListener('click', prevDisplacementImage);
        
        // Initialize
        updateDisplacementCarousel();
      })();
      </script>
    </div>
  </div>
</section>

<!-- SEC 5: Spelke Object Discovery Algorithm -->
<section class="section" style="padding-top: 1.75rem;">
  <div class="container is-max-desktop">
    <div class="content">
      <h2 class="has-text-weight-bold is-size-4 mb-4">Statistical counterfactual probing for Spelke object discovery</h2>

      <!-- Main body paragraph -->
      <div class="content has-text-justified mt-5 is-size-6">
        <p>
          Using these structure extractions, we first sample a location that is likely to move from \( p_{\text{motion}} \) and apply various virtual pokes at this location 
          in order to identify regions that consistently move together under various virtual pokes.
          We then compute the <strong>expected motion correlation</strong> by averaging across various pokes the dot product between the poke vector and associated \( \mathbb{E}_{\text{disp}} \). 
          Finally, Otsu's thresholding on the averaged dot product yields our desired Spelke segment.  
        </p>
        
        <!-- Object Discovery Carousel Container -->
        <div style="margin-top: 1rem; position: relative; max-width: 900px; margin-left: auto; margin-right: auto;">
          
          <!-- Carousel Videos Container -->
          <div id="discovery-carousel" style="position: relative; overflow: hidden; border-radius: 8px; background: #f5f5f5;">
            <div id="discovery-carousel-videos" style="display: flex; transition: transform 0.3s ease-in-out;">
              <video autoplay muted loop playsinline style="width: 100%; height: 650px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
                <source src="./static/videos/obj_discovery/2.mov" type="video/mp4">
              </video>
              <video autoplay muted loop playsinline style="width: 100%; height: 650px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
                <source src="./static/videos/obj_discovery/1.mov" type="video/mp4">
              </video>
              <video autoplay muted loop playsinline style="width: 100%; height: 650px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
                <source src="./static/videos/obj_discovery/3.mov" type="video/mp4">
              </video>
            </div>
          </div>
          
          <!-- Navigation Buttons -->
          <button id="discovery-prev-btn" style="position: absolute; left: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">‹</button>
          <button id="discovery-next-btn" style="position: absolute; right: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">›</button>
          
          <!-- Image Counter -->
          <div id="discovery-video-counter" style="position: absolute; bottom: 10px; right: 10px; background: rgba(0,0,0,0.7); color: white; padding: 4px 8px; border-radius: 12px; font-size: 12px; z-index: 10;">1 / 3</div>
        </div>
        
        <!-- Caption -->
        <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
          <strong>Spelke object discovery algorithm.</strong>
          Our approach can discover multiple objects within a scene and produces more meaningful segments that align with Spelke objects as compared to the SAM segments.
        </figcaption>
        
        <script>
        (function() {
          let discoveryCurrentIndex = 0;
          const discoveryTotalVideos = 3;
          const discoveryVideosPerView = 1;
          const discoveryMaxIndex = discoveryTotalVideos - discoveryVideosPerView; // 2 (positions 0-2)
          const discoveryCarouselVideos = document.getElementById('discovery-carousel-videos');
          const discoveryVideoCounter = document.getElementById('discovery-video-counter');
          const discoveryPrevBtn = document.getElementById('discovery-prev-btn');
          const discoveryNextBtn = document.getElementById('discovery-next-btn');
          
          function updateDiscoveryCarousel() {
            const translateX = -discoveryCurrentIndex * (100 / discoveryVideosPerView); // Move by 100%
            discoveryCarouselVideos.style.transform = `translateX(${translateX}%)`;
            
            const currentVideo = discoveryCurrentIndex + 1;
            discoveryVideoCounter.textContent = `${currentVideo} / ${discoveryTotalVideos}`;
          }
          
          function nextDiscoveryVideo() {
            if (discoveryCurrentIndex < discoveryMaxIndex) {
              discoveryCurrentIndex++;
            } else {
              discoveryCurrentIndex = 0; // Loop back to start
            }
            updateDiscoveryCarousel();
          }
          
          function prevDiscoveryVideo() {
            if (discoveryCurrentIndex > 0) {
              discoveryCurrentIndex--;
            } else {
              discoveryCurrentIndex = discoveryMaxIndex; // Loop to end
            }
            updateDiscoveryCarousel();
          }
          
          discoveryNextBtn.addEventListener('click', nextDiscoveryVideo);
          discoveryPrevBtn.addEventListener('click', prevDiscoveryVideo);
          
          // Initialize
          updateDiscoveryCarousel();
        })();
        </script>

        <div class="content has-text-justified mt-5 is-size-6" style="margin-top: 3rem;">
          <p>
            <strong>SpelkeNet achieves state-of-the-art performance on SpelkeBench. </strong> To evaluate our model's ability to discover Spelke objects, we formalize the
            task as point-promoted segmentation: given a single point on an object, the goal is to predict the Spelke segment associated with that point. 
            We find that SpelkeNet outperforms both self-supervised baselines (DINO, CWM) and the supervised SAM2 model on SpelkeBench.
          </p>
        </div>
        
        <!-- Quantitative Results Table -->
        <div class="content has-text-justified mt-5 is-size-6">
          <table style="margin: 0 auto; border-collapse: collapse; text-align: center;">
            <thead>
              <tr style="border-bottom: 2px solid #000;">
                <th style="padding: 8px 12px;"></th>
                <th style="padding: 8px 12px;"><a href="https://ai.meta.com/sam2/" target="_blank" rel="noopener noreferrer">SAM2</a></th>
                <th style="padding: 8px 12px;"><a href="https://github.com/facebookresearch/dino" target="_blank" rel="noopener noreferrer">DINOv1-B/8</a></th> 
                <th style="padding: 8px 12px;"><a href="https://dinov2.metademolab.com/" target="_blank" rel="noopener noreferrer">DINOv2-L/14</a></th> 
                <th style="padding: 8px 12px;"><a href="https://dinov2.metademolab.com/" target="_blank" rel="noopener noreferrer">DINOv2-G/14</a></th>
                <th style="padding: 8px 12px;"><a href="https://neuroailab.github.io/cwm-physics/" target="_blank" rel="noopener noreferrer">CWM</a></th>
                <th style="padding: 8px 12px;">SpelkeNet</th>
              </tr>
            </thead>
            <tbody>
              <tr style="border-bottom: 1px solid #ddd;">
                <td style="padding: 8px 12px; text-align: left;">AR</td>
                <td style="padding: 8px 12px;">0.4816</td>
                <td style="padding: 8px 12px;">0.2708</td>
                <td style="padding: 8px 12px;">0.2524</td>
                <td style="padding: 8px 12px;">0.2254</td>
                <td style="padding: 8px 12px;">0.3271</td>
                <td style="padding: 8px 12px; font-weight: bold;">0.5411</td>
              </tr>
              <tr style="border-bottom: 2px solid #000;">
                <td style="padding: 8px 12px; text-align: left;">mIoU</td>
                <td style="padding: 8px 12px;">0.6225</td>
                <td style="padding: 8px 12px;">0.4990</td>
                <td style="padding: 8px 12px;">0.4931</td>
                <td style="padding: 8px 12px;">0.4553</td>
                <td style="padding: 8px 12px;">0.4807</td>
                <td style="padding: 8px 12px; font-weight: bold;">0.6811</td>
              </tr>
            </tbody>
            <thead>
          </table>
          <caption class="is-size-6 has-text-grey mt-4" style="margin-bottom: 1rem; font-style: italic; text-align:justify">
            <strong>Evaluation of point-prompted segmentation accuracy.</strong> 
            We report Average Recall (AR) and mean Intersection over Union (mIoU) for various segmentation methods.
          </caption>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- SEC 6: Using Spelke Segments for Physically Plausible Object Manipulation -->
<section class="section" style="padding-top: 1.75rem;">
  <div class="container is-max-desktop">
    <div class="content">
      <h2 class="has-text-weight-bold is-size-4 mb-4">Using Spelke segments for physically plausible object manipulation</h2>
      
      <div class="content has-text-justified mt-5 is-size-6">
        <p>
          We consider the task of object-centric scene editing, where a user clicks a point on an object and provides an edit prompt specifying a 2D or 3D transformation. 
          A segmentation model generates an object edit mask from the point selection and the object manipulation method produces an edited image after applying the specified transformation to the object mask area.
          We show that SpelkeNet segments enable more physically plausible object editing as opposed to existing segmentation methods like SAM, which often split up or combine objects in ways that are inconsistent with how they move.
        </p>
      </div>
      
      <!-- Object Manipulation Carousel Container -->
      <div style="margin-top: 1rem; position: relative; max-width: 900px; margin-left: auto; margin-right: auto;">
        
        <!-- Carousel Videos Container -->
        <div id="manipulation-carousel" style="position: relative; overflow: hidden; border-radius: 8px; background: #f5f5f5;">
          <div id="manipulation-carousel-images" style="display: flex; transition: transform 0.3s ease-in-out;">
            <video autoplay muted loop playsinline style="width: 100%; height: 500px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
              <source src="./static/videos/objmanipulation/3.mov" type="video/mp4">
            </video>
            <video autoplay muted loop playsinline style="width: 100%; height: 500px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
              <source src="./static/videos/objmanipulation/2.mov" type="video/mp4">
            </video>
            <video autoplay muted loop playsinline style="width: 100%; height: 500px; object-fit: contain; flex-shrink: 0; background: white; padding: 0 5px;">
              <source src="./static/videos/objmanipulation/1.mov" type="video/mp4">
            </video>
          </div>
        </div>
        
        <!-- Navigation Buttons -->
        <button id="manipulation-prev-btn" style="position: absolute; left: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">‹</button>
        <button id="manipulation-next-btn" style="position: absolute; right: 10px; top: 50%; transform: translateY(-50%); background: rgba(0,0,0,0.7); color: white; border: none; border-radius: 50%; width: 40px; height: 40px; cursor: pointer; font-size: 18px; display: flex; align-items: center; justify-content: center; z-index: 10;">›</button>
        
        <!-- Image Counter -->
        <div id="manipulation-image-counter" style="position: absolute; bottom: 10px; right: 10px; background: rgba(0,0,0,0.7); color: white; padding: 4px 8px; border-radius: 12px; font-size: 12px; z-index: 10;">1 / 3</div>
      </div>
      
      <!-- Caption -->
      <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
        <strong>Comparison of SpelkeNet and SAM in an object manipulation pipeline.</strong> 
        From a single-point segmentation prompt, the generated segment and edit prompt is used as input to  <a href="https://neuroailab.github.io/projects/lras_3d/" target="_blank" rel="noopener noreferrer">LRAS-3D</a>, a state-of-the-art object manipulation editing method.
      </figcaption>
      
      <script>
      (function() {
        let manipulationCurrentIndex = 0;
        const manipulationTotalImages = 3;
        const manipulationImagesPerView = 1;
        const manipulationMaxIndex = manipulationTotalImages - manipulationImagesPerView; // 2 (positions 0-2)
        const manipulationCarouselImages = document.getElementById('manipulation-carousel-images');
        const manipulationImageCounter = document.getElementById('manipulation-image-counter');
        const manipulationPrevBtn = document.getElementById('manipulation-prev-btn');
        const manipulationNextBtn = document.getElementById('manipulation-next-btn');
        
        function updateManipulationCarousel() {
          const translateX = -manipulationCurrentIndex * (100 / manipulationImagesPerView); // Move by 100%
          manipulationCarouselImages.style.transform = `translateX(${translateX}%)`;
          
          const currentImage = manipulationCurrentIndex + 1;
          manipulationImageCounter.textContent = `${currentImage} / ${manipulationTotalImages}`;
        }
        
        function nextManipulationImage() {
          if (manipulationCurrentIndex < manipulationMaxIndex) {
            manipulationCurrentIndex++;
          } else {
            manipulationCurrentIndex = 0; // Loop back to start
          }
          updateManipulationCarousel();
        }
        
        function prevManipulationImage() {
          if (manipulationCurrentIndex > 0) {
            manipulationCurrentIndex--;
          } else {
            manipulationCurrentIndex = manipulationMaxIndex; // Loop to end
          }
          updateManipulationCarousel();
        }
        
        manipulationNextBtn.addEventListener('click', nextManipulationImage);
        manipulationPrevBtn.addEventListener('click', prevManipulationImage);
        
        // Initialize
        updateManipulationCarousel();
      })();
      </script>

      <div class="content has-text-justified mt-5 is-size-6" style="margin-top: 3rem;">
        <p>
          <strong>Across various object manipulation pipelines, Spelke segments yield more physically plausible object edits.</strong> To evaluate the utility of SpelkeNet segments for object manipulation, we replace SAM with SpelkeNet in the pipeline for existing object editing models.
          Specifically, we use <a href="https://neuroailab.github.io/projects/lras_3d/" target="_blank" rel="noopener noreferrer"><strong>3DEditBench</strong></a>, a benchmark containing 100 image pairs with associated ground truth point prompts and 3D scene edits (e.g. rotations, translations). 
          From the table below, we show that for existing object manipulation methods, SpelkeNet segments improve performance significantly.
        </p>
      </div>

      <div class="content has-text-justified mt-5 is-size-6">
        <table style="margin: 0 auto; border-collapse: collapse; text-align: center;">
          <thead>
            <tr style="border-bottom: 2px solid #000;">
              <th style="padding: 8px 12px;">Method</th>
              <th style="padding: 8px 12px;">Segment</th>
              <th style="padding: 8px 12px;">MSE ↓</th>
              <th style="padding: 8px 12px;">PSNR ↑</th>
              <th style="padding: 8px 12px;">LPIPS ↓</th>
              <th style="padding: 8px 12px;">SSIM ↑</th>
              <th style="padding: 8px 12px;">EA ↑</th>
            </tr>
          </thead>
          <tbody>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px; text-align: left;" rowspan="2"><a href="https://neuroailab.github.io/projects/lras_3d/" target="_blank" rel="noopener noreferrer">LRAS-3D</a></td>
              <td style="padding: 8px 12px;">SpelkeNet</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.009</td>
              <td style="padding: 8px 12px; font-weight: bold;">21.64</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.213</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.698</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.776</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px;">SAM</td>
              <td style="padding: 8px 12px;">0.013</td>
              <td style="padding: 8px 12px;">20.17</td>
              <td style="padding: 8px 12px;">0.255</td>
              <td style="padding: 8px 12px;">0.685</td>
              <td style="padding: 8px 12px;">0.633</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px; text-align: left;" rowspan="2"><a href="https://lightning-drag.github.io/" target="_blank" rel="noopener noreferrer">LightningDrag</a></td>
              <td style="padding: 8px 12px;">SpelkeNet</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.017</td>
              <td style="padding: 8px 12px; font-weight: bold;">19.16</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.195</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.672</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.679</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px;">SAM</td>
              <td style="padding: 8px 12px;">0.020</td>
              <td style="padding: 8px 12px;">18.18</td>
              <td style="padding: 8px 12px;">0.241</td>
              <td style="padding: 8px 12px;">0.658</td>
              <td style="padding: 8px 12px;">0.536</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px; text-align: left;" rowspan="2"><a href="https://diffusionhandles.github.io/" target="_blank" rel="noopener noreferrer">Diffusion Handles</a></td>
              <td style="padding: 8px 12px;">SpelkeNet</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.024</td>
              <td style="padding: 8px 12px; font-weight: bold;">17.42</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.364</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.555</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.576</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px;">SAM</td>
              <td style="padding: 8px 12px;">0.031</td>
              <td style="padding: 8px 12px;">16.15</td>
              <td style="padding: 8px 12px;">0.419</td>
              <td style="padding: 8px 12px;">0.526</td>
              <td style="padding: 8px 12px;">0.495</td>
            </tr>
            <tr style="border-bottom: 1px solid #ddd;">
              <td style="padding: 8px 12px; text-align: left;" rowspan="2"><a href="https://igl-hkust.github.io/das/" target="_blank" rel="noopener noreferrer">Diffusion as Shader</a></td>
              <td style="padding: 8px 12px;">SpelkeNet</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.015</td>
              <td style="padding: 8px 12px; font-weight: bold;">19.29</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.194</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.707</td>
              <td style="padding: 8px 12px; font-weight: bold;">0.640</td>
            </tr>
            <tr style="border-bottom: 2px solid #000;">
              <td style="padding: 8px 12px;">SAM</td>
              <td style="padding: 8px 12px;">0.019</td>
              <td style="padding: 8px 12px;">18.20</td>
              <td style="padding: 8px 12px;">0.253</td>
              <td style="padding: 8px 12px;">0.682</td>
              <td style="padding: 8px 12px;">0.503</td>
            </tr>
          </tbody>
        </table>
        <caption class="is-size-6 has-text-grey mt-4" style="margin-bottom: 1rem; font-style: italic; text-align:justify">
          <strong>Evaluation of edit quality across segmentation methods and editing pipelines.</strong> We report results for edits generated using SAM versus SpelkeNet segments across four editing models. Lower ↓ is better, higher ↑ is better.
        </caption>
      </div>
    </div>
  </div>
</section>

<!-- SEC 7: Emergent Properties -->
<section class="section" style="padding-top: 1.75rem;">
  <div class="container is-max-desktop">
    <div class="content">
      <h2 class="has-text-weight-bold is-size-4 mb-4">Emergent properties of SpelkeNet</h2>
      
      <div class="content has-text-justified mt-5 is-size-6">
        <p>
          We have demonstrated SpelkeNet's utility in discovering Spelke segments and shown how these segments enable more realistic scene edits in object manipulation pipelines. 
          Beyond these applications, SpelkeNet also exhibits emergent properties that reveal a deeper understanding of physical scene structure.
        </p>
      </div>

      <!-- Subsection 1: Material Property Understanding -->
      <div class="content has-text-justified mt-5 is-size-6" style="margin-top: 3rem;">
        
        <figure class="image is-inline-block has-text-centered">
          <img src="./static/images/material.png" alt="Material Understanding" style="height: 500px; object-fit: contain; max-width: 100%;">
          <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
            <strong>Material property understanding.</strong> The generated \( p_{\text{motion}} \) maps can be used to infer physical attributes such as rigidity or material type.
            Rigid objects like laptops and cardboard boxes tend to exhibit a
          uniform probability across the segment, while deformable objects such as cloth and plastic covers
          often show more localized motion responses near the poke point.
          </figcaption>
        </figure>
      </div>

      <!-- Subsection 2: Understanding Support Relationships -->
      <div class="content has-text-justified mt-5 is-size-6" style="margin-top: 3rem;">
        <figure class="image is-inline-block has-text-centered">
          <img src="./static/images/supp_relationships.png" alt="Support Relationships" style="height: 500px; object-fit: contain; max-width: 100%;">
          <figcaption class="is-size-6 has-text-grey mt-2" style="font-style: italic; text-align:justify">
            <strong>Support relationships understanding.</strong> When applying a virtual poke to an object within a stack (e.g. the bottom book), the extracted Spelke segment includes both the poked object and all the objects it physically supports, implying an understanding of support hierarchies within a scene.
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{venkatesh2025discoveringandusingsegments,
  title        = {Discovering and using Spelke segments}, 
  author       = {Rahul Venkatesh and Klemen Kotar and Lilian Naing Chen and Seoungwoo Kim and Luca Thomas Wheeler and Jared Watrous and Ashley Xu and Gia Ancone and Wanhee Lee and Honglin Chen and Daniel Bear and Stefan Stojanov and Daniel Yamins},
  year         = {2025},
  eprint       = {TODO},
  archivePrefix = {arXiv},
  primaryClass = {cs.CV},
  url          = {TODO}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>